{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad03d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧹 images 폴더 초기화 완료\n",
      "🧹 start_time.txt 초기화 완료\n",
      "🆕 start_time.txt 없음 → 사용자 입력 필요\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import csv\n",
    "import sys\n",
    "import uuid\n",
    "import requests\n",
    "import pymysql\n",
    "from datetime import datetime, timedelta\n",
    "from bs4 import BeautifulSoup\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 환경변수 로딩\n",
    "load_dotenv()\n",
    "sys.argv = ['notebook', '--clear-csv', '--clear-images', '--reset', '--clear-links']\n",
    "\n",
    "CRAWLED_LINKS_FILE = 'crawled_links.txt'\n",
    "START_TIME_FILE = 'start_time.txt'\n",
    "DATETIME_FORMAT = \"%Y-%m-%d %H:%M:%S\"\n",
    "LOG_DIR = 'logs'\n",
    "LOG_FILE = os.path.join(LOG_DIR, 'crawl_log.log')\n",
    "os.makedirs(LOG_DIR, exist_ok=True)\n",
    "os.makedirs('images', exist_ok=True)\n",
    "\n",
    "def load_official_club_info():\n",
    "    url = \"https://www.kumoh.ac.kr/ko/sub04_01_02.do\"\n",
    "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.encoding = 'utf-8'\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        club_dict = {}\n",
    "\n",
    "        for area in soup.select(\"div.contents-area\"):\n",
    "            category_tag = area.select_one(\"h4.title0401\")\n",
    "            table = area.select_one(\"div.table-type01\")\n",
    "            if not category_tag or not table:\n",
    "                continue\n",
    "            category = category_tag.text.strip()\n",
    "            for row in table.select(\"tbody tr\"):\n",
    "                cols = row.select(\"td\")\n",
    "                if not cols:\n",
    "                    continue\n",
    "                name = cols[0].text.strip()\n",
    "                simplified = re.sub(r'[^\\w]', '', name).upper()\n",
    "                club_dict[name] = {\"category\": category}\n",
    "                club_dict[simplified] = {\"category\": category, \"original\": name}\n",
    "        return club_dict\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] 동아리 정보 로딩 실패: {e}\")\n",
    "        return {}\n",
    "\n",
    "if '--clear-csv' in sys.argv and os.path.exists('everytime_output.csv'):\n",
    "    os.remove('everytime_output.csv')\n",
    "    print(\"🧹 everytime_output.csv 초기화 완료\")\n",
    "if '--clear-images' in sys.argv:\n",
    "    for img_file in os.listdir('images'):\n",
    "        img_path = os.path.join('images', img_file)\n",
    "        if os.path.isfile(img_path):\n",
    "            os.remove(img_path)\n",
    "    print(\"🧹 images 폴더 초기화 완료\")\n",
    "if '--reset' in sys.argv and os.path.exists(START_TIME_FILE):\n",
    "    os.remove(START_TIME_FILE)\n",
    "    print(\"🧹 start_time.txt 초기화 완료\")\n",
    "if '--clear-links' in sys.argv and os.path.exists(CRAWLED_LINKS_FILE):\n",
    "    os.remove(CRAWLED_LINKS_FILE)\n",
    "    print(\"🧹 crawled_links.txt 초기화 완료\")\n",
    "\n",
    "def log(message):\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    with open(LOG_FILE, 'a', encoding='utf-8') as f:\n",
    "        f.write(f\"[{timestamp}] {message}\\n\")\n",
    "    print(message)\n",
    "\n",
    "def get_club_id_by_name(cursor, club_name):\n",
    "    if not club_name:\n",
    "        return None\n",
    "    cursor.execute(\"SELECT clubId FROM Club WHERE clubName LIKE %s\", (f\"%{club_name}%\",))\n",
    "    result = cursor.fetchone()\n",
    "    return result[0] if result else None\n",
    "\n",
    "def write_to_db_by_category(row):\n",
    "    try:\n",
    "        conn = pymysql.connect(\n",
    "            host=os.getenv(\"DB_HOST\"),\n",
    "            port=int(os.getenv(\"DB_PORT\")),\n",
    "            user=os.getenv(\"DB_USER\"),\n",
    "            password=os.getenv(\"DB_PASSWORD\"),\n",
    "            database=os.getenv(\"DB_NAME\"),\n",
    "            charset='utf8mb4',\n",
    "            autocommit=True\n",
    "        )\n",
    "        with conn.cursor() as cursor:\n",
    "            club_id = get_club_id_by_name(cursor, row[\"club_name\"])\n",
    "            if not club_id:\n",
    "                log(f\"[SKIP] club_name 매칭 실패: {row['club_name']}\")\n",
    "                return\n",
    "\n",
    "            if row[\"category\"] == \"모집\":\n",
    "                sql = \"\"\"\n",
    "                    INSERT INTO ClubPromotion (clubId, target, dues, interview, endDate, isRecruiting)\n",
    "                    VALUES (%s, %s, %s, %s, %s, %s)\n",
    "                \"\"\"\n",
    "                cursor.execute(sql, (\n",
    "                    club_id,\n",
    "                    row.get(\"target\", \"무관\"),\n",
    "                    row.get(\"dues\", 0),\n",
    "                    row.get(\"interview\", 0),\n",
    "                    row[\"deadline\"] if row[\"deadline\"] != \"상시\" else None,\n",
    "                    1\n",
    "                ))\n",
    "                log(f\"✅ ClubPromotion 저장: {row['title'][:20]}\")\n",
    "            else:\n",
    "                post_num = uuid.uuid4().hex\n",
    "                cursor.execute(\"\"\"\n",
    "                    INSERT INTO Post (postNum, title, content, type, file, `like`, fixaction, date)\n",
    "                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s)\n",
    "                \"\"\", (\n",
    "                    post_num,\n",
    "                    row[\"title\"],\n",
    "                    row[\"content\"],\n",
    "                    4,  # ✅ 홍보 포스터로 고정\n",
    "                    None,\n",
    "                    0,\n",
    "                    0,\n",
    "                    datetime.now()\n",
    "                ))\n",
    "                cursor.execute(\"\"\"\n",
    "                    INSERT INTO ClubPost (postNum, clubId)\n",
    "                    VALUES (%s, %s)\n",
    "                \"\"\", (post_num, club_id))\n",
    "                for img_path in row.get(\"images\", []):\n",
    "                    cursor.execute(\"\"\"\n",
    "                        INSERT INTO Poster (postNum, img)\n",
    "                        VALUES (%s, %s)\n",
    "                    \"\"\", (post_num, img_path))\n",
    "                log(f\"✅ Post + ClubPost + Poster 저장: {row['title'][:20]}\")\n",
    "        conn.close()\n",
    "    except Exception as e:\n",
    "        log(f\"[DB ERROR] 저장 실패: {e}\")\n",
    "\n",
    "def load_start_time():\n",
    "    if os.path.exists(START_TIME_FILE):\n",
    "        log(\"📁 start_time.txt 파일 발견 → 불러옴\")\n",
    "        with open(START_TIME_FILE, 'r') as f:\n",
    "            return datetime.strptime(f.read().strip(), DATETIME_FORMAT)\n",
    "    else:\n",
    "        log(\"🆕 start_time.txt 없음 → 사용자 입력 필요\")\n",
    "        start_date = input('Start Date (YYYY-MM-DD): ')\n",
    "        dt = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "        save_start_time(dt)\n",
    "        return dt\n",
    "\n",
    "def save_start_time(dt):\n",
    "    with open(START_TIME_FILE, 'w') as f:\n",
    "        f.write(dt.strftime(DATETIME_FORMAT))\n",
    "\n",
    "def login_everytime(driver):\n",
    "    id = os.getenv(\"EVERYTIME_ID\")\n",
    "    pw = os.getenv(\"EVERYTIME_PW\")\n",
    "\n",
    "    if not id or not pw:\n",
    "        log(\"❌ .env에 EVERYTIME_ID 또는 EVERYTIME_PW가 설정되지 않았습니다.\")\n",
    "        return\n",
    "\n",
    "    # 자동화 탐지 우회 스크립트 삽입\n",
    "    driver.execute_cdp_cmd(\"Page.addScriptToEvaluateOnNewDocument\", {\n",
    "        \"source\": \"\"\"\n",
    "        Object.defineProperty(navigator, 'webdriver', {\n",
    "            get: () => undefined\n",
    "        })\n",
    "        \"\"\"\n",
    "    })\n",
    "\n",
    "    while True:\n",
    "        driver.get(\"https://account.everytime.kr/login\")\n",
    "        log(\"🌐 Everytime 로그인 페이지 로딩 중...\")\n",
    "        \n",
    "        try:\n",
    "            WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.NAME, 'id'))).send_keys(id)\n",
    "            driver.find_element(By.NAME, 'password').send_keys(pw)\n",
    "        except Exception as e:\n",
    "            log(f\"[ERROR] 로그인 입력창 로딩 실패: {e}\")\n",
    "            continue  # 재시도\n",
    "\n",
    "        try:\n",
    "            ActionChains(driver).move_to_element(driver.find_element(By.CSS_SELECTOR, \"body\")).click().perform()\n",
    "            log(\"🖱 빈 공간 클릭 완료 (자동화 우회)\")\n",
    "        except Exception as e:\n",
    "            log(f\"[!] 빈 공간 클릭 실패: {e}\")\n",
    "        time.sleep(2)\n",
    "        log(\"🔑 로그인 시도 중...\")\n",
    "        driver.find_element(By.CSS_SELECTOR, 'input[type=\"submit\"]').click()\n",
    "        time.sleep(2)\n",
    "\n",
    "        try:\n",
    "            WebDriverWait(driver, 3).until(EC.alert_is_present())\n",
    "            alert = driver.switch_to.alert\n",
    "            log(f\"⚠️ 경고창 감지: {alert.text}\")\n",
    "            alert.accept()\n",
    "            log(\"🔄 로그인 재시도 중...\")\n",
    "            driver.refresh()\n",
    "            continue\n",
    "        except:\n",
    "            # 경고창 없으면 로그인 성공 여부 확인\n",
    "            if \"login\" in driver.current_url:\n",
    "                log(\"⚠️ 로그인 실패: 경고창은 없지만 로그인 상태 아님 → 재시도\")\n",
    "                continue\n",
    "\n",
    "            log(\"✅ 로그인 성공 확인됨\")\n",
    "            break\n",
    "\n",
    "\n",
    "def write_csv(row):\n",
    "    file_exists = os.path.exists('everytime_output.csv')\n",
    "    with open('everytime_output.csv', 'a', encoding='utf-8', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        if not file_exists:\n",
    "            writer.writerow(['작성일시', '제목', '내용', '카테고리', '마감일', '전화번호', 'URL', '동아리명', '이미지들', '동아리분야'])\n",
    "        writer.writerow(row)\n",
    "\n",
    "def download_image(img_url):\n",
    "    try:\n",
    "        if any(kw in img_url for kw in [\"nav.logo\", \"favicon\", \"cf-fpi.everytime.kr/0.png\"]):\n",
    "            log(f\"[SKIP] 불필요 이미지 필터링됨: {img_url}\")\n",
    "            return \"\"\n",
    "\n",
    "        response = requests.get(img_url, timeout=10)\n",
    "        img = Image.open(BytesIO(response.content))\n",
    "\n",
    "        if img.mode in (\"RGBA\", \"P\"):\n",
    "            img = img.convert(\"RGB\")\n",
    "\n",
    "        # ✅ 비율 유지하며 최대 720x1080 안으로 축소\n",
    "        max_width, max_height = 720, 1080\n",
    "        orig_w, orig_h = img.size\n",
    "        ratio = min(max_width / orig_w, max_height / orig_h, 1.0)  # 원본이 작으면 그대로\n",
    "        new_size = (int(orig_w * ratio), int(orig_h * ratio))\n",
    "        img = img.resize(new_size, Image.LANCZOS)\n",
    "\n",
    "        # ✅ 저장 경로\n",
    "        filename = f\"img_{uuid.uuid4().hex}.jpg\"\n",
    "        path = os.path.join(\"images\", filename)\n",
    "\n",
    "        # ✅ 고화질 JPEG 저장\n",
    "        img.save(path, format=\"JPEG\", quality=95, optimize=True, progressive=True)\n",
    "\n",
    "        log(f\"🖼 이미지 저장 완료: {filename} ({new_size[0]}x{new_size[1]})\")\n",
    "        return filename\n",
    "\n",
    "    except Exception as e:\n",
    "        log(f\"[!] 이미지 저장 실패: {img_url} → {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def parse_post_time(text):\n",
    "    now = datetime.now()\n",
    "    if '방금' in text:\n",
    "        return now\n",
    "    if '분 전' in text:\n",
    "        m = re.search(r'(\\d+)', text)\n",
    "        return now - timedelta(minutes=int(m.group(1))) if m else None\n",
    "    if re.match(r'\\d{2}/\\d{2} \\d{2}:\\d{2}', text):\n",
    "        month, day, hour, minute = map(int, re.findall(r'\\d+', text))\n",
    "        year = now.year\n",
    "        dt = datetime(year, month, day, hour, minute)\n",
    "        if dt > now and month in [11, 12]:\n",
    "            dt = datetime(year - 1, month, day, hour, minute)\n",
    "        return dt\n",
    "    if re.match(r'\\d{2}/\\d{2}$', text):\n",
    "        month, day = map(int, re.findall(r'\\d+', text))\n",
    "        year = now.year\n",
    "        dt = datetime(year, month, day)\n",
    "        if dt > now and month in [11, 12]:\n",
    "            dt = datetime(year - 1, month, day)\n",
    "        return dt\n",
    "    return None\n",
    "\n",
    "def extract_deadline(content, post_time):\n",
    "    content = re.sub(r'01[0-9][-\\.\\s]?[0-9]{3,4}[-\\.\\s]?[0-9]{4}', '', content)\n",
    "    range_patterns = [r'(\\d{1,2})[./](\\d{1,2})\\s*[~\\-]\\s*(\\d{1,2})[./](\\d{1,2})']\n",
    "    for pattern in range_patterns:\n",
    "        match = re.search(pattern, content)\n",
    "        if match:\n",
    "            sm, sd, em, ed = map(int, match.groups())\n",
    "            try:\n",
    "                deadline = datetime(post_time.year, em, ed)\n",
    "                if deadline < post_time:\n",
    "                    deadline = datetime(post_time.year + 1, em, ed)\n",
    "                return deadline.strftime(\"%Y-%m-%d\")\n",
    "            except:\n",
    "                continue\n",
    "    patterns = [\n",
    "        r'(\\d{4})년\\s*(\\d{1,2})월\\s*(\\d{1,2})일',\n",
    "        r'(\\d{1,2})월\\s*(\\d{1,2})일',\n",
    "        r'(\\d{1,2})/(\\d{1,2})',\n",
    "        r'(?<!\\d)(0[1-9]|1[0-2])\\.(0[1-9]|[12][0-9]|3[01])(?!\\d)'\n",
    "    ]\n",
    "    for pattern in patterns:\n",
    "        matches = re.findall(pattern, content)\n",
    "        for match in matches:\n",
    "            try:\n",
    "                if len(match) == 3:\n",
    "                    year, month, day = map(int, match)\n",
    "                else:\n",
    "                    month, day = map(int, match)\n",
    "                    year = post_time.year\n",
    "                deadline = datetime(year, month, day)\n",
    "                if deadline < post_time:\n",
    "                    deadline = datetime(year + 1, month, day)\n",
    "                return deadline.strftime(\"%Y-%m-%d\")\n",
    "            except:\n",
    "                continue\n",
    "    if '매주' in content or '매일' in content or '정기' in content:\n",
    "        return None\n",
    "    return None\n",
    "\n",
    "def analyze_post(title, content, post_time, official_clubs):\n",
    "    category = \"홍보\"\n",
    "    phone = \"\"\n",
    "\n",
    "    if \"박람회\" in title or \"박람회\" in content:\n",
    "        category = \"홍보\"\n",
    "    elif \"모집\" in title or \"모집\" in content:\n",
    "        category = \"모집\"\n",
    "\n",
    "    phone_match = re.search(r'01[0-9][-]\\d{3,4}-\\d{4}', content)\n",
    "    if phone_match:\n",
    "        phone = phone_match.group()\n",
    "\n",
    "    combined_text = (title + \" \" + content)\n",
    "    simplified_text = re.sub(r'[^\\w]', '', combined_text).upper()\n",
    "\n",
    "    matched_club = \"\"\n",
    "    matched_category = \"\"\n",
    "    for key, info in official_clubs.items():\n",
    "        if key in combined_text or key in simplified_text:\n",
    "            matched_club = info.get(\"original\", key)\n",
    "            matched_category = info[\"category\"]\n",
    "            break\n",
    "\n",
    "    if matched_club:\n",
    "        club_name = matched_club\n",
    "    else:\n",
    "        club_name = \"\"\n",
    "\n",
    "    deadline = extract_deadline(content, post_time)\n",
    "    if category == \"홍보\":\n",
    "        deadline = \"\"\n",
    "\n",
    "    return category, deadline, phone, club_name, matched_category\n",
    "\n",
    "def extract_images_excluding_profile(soup):\n",
    "    img_urls = []\n",
    "    for article in soup.select('article'):\n",
    "        all_imgs = article.select('img')\n",
    "        skip_first = True\n",
    "        for img in all_imgs:\n",
    "            src = img.get('src') or img.get('data-src') or img.get('lazy-src')\n",
    "            if not src:\n",
    "                continue\n",
    "            if skip_first or 'picture' in img.get('class', []) or src == 'https://cf-fpi.everytime.kr/0.png':\n",
    "                log(f\"[SKIP] 프로필 이미지 제외됨: {src}\")\n",
    "                skip_first = False\n",
    "                continue\n",
    "            if src.startswith('//'):\n",
    "                src = 'https:' + src\n",
    "            elif src.startswith('/'):\n",
    "                src = 'https://everytime.kr' + src\n",
    "            if re.search(r'\\.(png|jpg|jpeg|gif|webp)(\\?|$)', src, re.IGNORECASE):\n",
    "                img_urls.append(src)\n",
    "    return img_urls\n",
    "\n",
    "def run(driver, start_datetime, end_datetime):\n",
    "    official_clubs = load_official_club_info()\n",
    "    board_id = \"418897\"\n",
    "    base_url = f\"https://everytime.kr/{board_id}/p/\"\n",
    "    crawled_links = set()\n",
    "    if os.path.exists(CRAWLED_LINKS_FILE):\n",
    "        with open(CRAWLED_LINKS_FILE, 'r', encoding='utf-8') as f:\n",
    "            crawled_links = set(f.read().splitlines())\n",
    "\n",
    "    for page in range(1, 1000):\n",
    "        try:\n",
    "            url = base_url + str(page)\n",
    "            log(f\"[DEBUG] ▶ 페이지 이동: {url}\")\n",
    "            driver.get(url)\n",
    "            time.sleep(2)\n",
    "            WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, 'articles')))\n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            articles = soup.select(\"article\")\n",
    "            valid_post_count = 0\n",
    "            for article in articles:\n",
    "                link_tag = article.find(\"a\", href=True)\n",
    "                if not link_tag or not link_tag.has_attr(\"href\"):\n",
    "                    continue\n",
    "                href = link_tag['href']\n",
    "                if not re.search(r\"/v/\\d+\", href):\n",
    "                    continue\n",
    "                time_tag = link_tag.find(\"time\")\n",
    "                if not time_tag:\n",
    "                    continue\n",
    "                post_time = parse_post_time(time_tag.text.strip())\n",
    "                if not post_time or not (start_datetime <= post_time < end_datetime):\n",
    "                    continue\n",
    "                full_url = f\"https://everytime.kr{href}\"\n",
    "                if full_url in crawled_links:\n",
    "                    continue\n",
    "\n",
    "                driver.get(full_url)\n",
    "                WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.TAG_NAME, 'article')))\n",
    "                soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "                post = soup.find(\"article\")\n",
    "                title = post.h2.text.strip()\n",
    "                content = post.find('p').get_text(separator='\\n').strip()\n",
    "                category, deadline, phone, club_name, club_category = analyze_post(title, content, post_time, official_clubs)\n",
    "                if '피험자' in title or '피험자' in content:\n",
    "                    log(f\"[SKIP] 피험자 모집 감지: {title[:20]}... ({club_name})\")\n",
    "                    continue\n",
    "\n",
    "                semester = f\"{post_time.year}-S{1 if post_time.month <= 6 else 2}\"\n",
    "                if f\"{semester}|{title.strip()}\" in crawled_links:\n",
    "                    log(f\"[SKIP] 제목 완전 일치 중복 감지: {title[:20]}... ({club_name})\")\n",
    "                    continue\n",
    "\n",
    "                is_similar = False\n",
    "                for key in crawled_links:\n",
    "                    if key.startswith(semester):\n",
    "                        existing_title = key.split('|', 1)[-1]\n",
    "                        tfidf = TfidfVectorizer().fit_transform([title.strip(), existing_title])\n",
    "                        sim = cosine_similarity(tfidf[0:1], tfidf[1:2])[0][0]\n",
    "                        if sim > 0.85:\n",
    "                            log(f\"[SKIP] 유사 제목 중복 감지 (cos {sim:.2f}): {title[:20]}... ({club_name})\")\n",
    "                            is_similar = True\n",
    "                            break\n",
    "                if is_similar:\n",
    "                    continue\n",
    "\n",
    "                # 이미지 추출 및 저장\n",
    "                img_urls = extract_images_excluding_profile(soup)\n",
    "                saved_imgs = [download_image(img_url) for img_url in img_urls]\n",
    "\n",
    "                write_to_db_by_category({\n",
    "                    \"title\": title,\n",
    "                    \"content\": content,\n",
    "                    \"category\": category,\n",
    "                    \"deadline\": deadline if deadline else \"상시\",\n",
    "                    \"phone\": phone,\n",
    "                    \"url\": full_url,\n",
    "                    \"club_name\": club_name,\n",
    "                    \"images\": saved_imgs\n",
    "                })\n",
    "\n",
    "                crawled_links.add(full_url)\n",
    "                crawled_links.add(f\"{semester}|{title.strip()}\")\n",
    "                log(f\"📄 {post_time.strftime('%m/%d')} - {title} [{category}] ({club_name}) 저장\")\n",
    "                valid_post_count += 1\n",
    "\n",
    "            if valid_post_count == 0:\n",
    "                log(\"🛑 현재 페이지 모든 게시글이 범위 밖 → 크롤링 종료\")\n",
    "                break\n",
    "\n",
    "        except Exception as e:\n",
    "            log(f\"[!] 페이지 {page} 처리 실패: {e}\")\n",
    "            continue\n",
    "\n",
    "def main():\n",
    "    while True:\n",
    "        start_datetime = load_start_time()\n",
    "        end_datetime = datetime.now()\n",
    "        options = webdriver.ChromeOptions()\n",
    "        options.add_argument('window-size=1200x800')\n",
    "        driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "        login_everytime(driver)\n",
    "        log(f\"🌐 크롤링 시작: {end_datetime.strftime(DATETIME_FORMAT)}\")\n",
    "        log(f\"📆 크롤링 범위: {start_datetime.strftime(DATETIME_FORMAT)} ~ {end_datetime.strftime(DATETIME_FORMAT)}\")\n",
    "        run(driver, start_datetime, end_datetime)\n",
    "        save_start_time(end_datetime)\n",
    "        driver.quit()\n",
    "        log(\"⏳ 1시간 대기 중...\\n\")\n",
    "        time.sleep(3600)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
