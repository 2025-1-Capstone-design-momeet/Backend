{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad03d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§¹ images í´ë” ì´ˆê¸°í™” ì™„ë£Œ\n",
      "ğŸ§¹ start_time.txt ì´ˆê¸°í™” ì™„ë£Œ\n",
      "ğŸ†• start_time.txt ì—†ìŒ â†’ ì‚¬ìš©ì ì…ë ¥ í•„ìš”\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import csv\n",
    "import sys\n",
    "import uuid\n",
    "import requests\n",
    "import pymysql\n",
    "from datetime import datetime, timedelta\n",
    "from bs4 import BeautifulSoup\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# í™˜ê²½ë³€ìˆ˜ ë¡œë”©\n",
    "load_dotenv()\n",
    "sys.argv = ['notebook', '--clear-csv', '--clear-images', '--reset', '--clear-links']\n",
    "\n",
    "CRAWLED_LINKS_FILE = 'crawled_links.txt'\n",
    "START_TIME_FILE = 'start_time.txt'\n",
    "DATETIME_FORMAT = \"%Y-%m-%d %H:%M:%S\"\n",
    "LOG_DIR = 'logs'\n",
    "LOG_FILE = os.path.join(LOG_DIR, 'crawl_log.log')\n",
    "os.makedirs(LOG_DIR, exist_ok=True)\n",
    "os.makedirs('images', exist_ok=True)\n",
    "\n",
    "def load_official_club_info():\n",
    "    url = \"https://www.kumoh.ac.kr/ko/sub04_01_02.do\"\n",
    "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.encoding = 'utf-8'\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        club_dict = {}\n",
    "\n",
    "        for area in soup.select(\"div.contents-area\"):\n",
    "            category_tag = area.select_one(\"h4.title0401\")\n",
    "            table = area.select_one(\"div.table-type01\")\n",
    "            if not category_tag or not table:\n",
    "                continue\n",
    "            category = category_tag.text.strip()\n",
    "            for row in table.select(\"tbody tr\"):\n",
    "                cols = row.select(\"td\")\n",
    "                if not cols:\n",
    "                    continue\n",
    "                name = cols[0].text.strip()\n",
    "                simplified = re.sub(r'[^\\w]', '', name).upper()\n",
    "                club_dict[name] = {\"category\": category}\n",
    "                club_dict[simplified] = {\"category\": category, \"original\": name}\n",
    "        return club_dict\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] ë™ì•„ë¦¬ ì •ë³´ ë¡œë”© ì‹¤íŒ¨: {e}\")\n",
    "        return {}\n",
    "\n",
    "if '--clear-csv' in sys.argv and os.path.exists('everytime_output.csv'):\n",
    "    os.remove('everytime_output.csv')\n",
    "    print(\"ğŸ§¹ everytime_output.csv ì´ˆê¸°í™” ì™„ë£Œ\")\n",
    "if '--clear-images' in sys.argv:\n",
    "    for img_file in os.listdir('images'):\n",
    "        img_path = os.path.join('images', img_file)\n",
    "        if os.path.isfile(img_path):\n",
    "            os.remove(img_path)\n",
    "    print(\"ğŸ§¹ images í´ë” ì´ˆê¸°í™” ì™„ë£Œ\")\n",
    "if '--reset' in sys.argv and os.path.exists(START_TIME_FILE):\n",
    "    os.remove(START_TIME_FILE)\n",
    "    print(\"ğŸ§¹ start_time.txt ì´ˆê¸°í™” ì™„ë£Œ\")\n",
    "if '--clear-links' in sys.argv and os.path.exists(CRAWLED_LINKS_FILE):\n",
    "    os.remove(CRAWLED_LINKS_FILE)\n",
    "    print(\"ğŸ§¹ crawled_links.txt ì´ˆê¸°í™” ì™„ë£Œ\")\n",
    "\n",
    "def log(message):\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    with open(LOG_FILE, 'a', encoding='utf-8') as f:\n",
    "        f.write(f\"[{timestamp}] {message}\\n\")\n",
    "    print(message)\n",
    "\n",
    "def get_club_id_by_name(cursor, club_name):\n",
    "    if not club_name:\n",
    "        return None\n",
    "    cursor.execute(\"SELECT clubId FROM Club WHERE clubName LIKE %s\", (f\"%{club_name}%\",))\n",
    "    result = cursor.fetchone()\n",
    "    return result[0] if result else None\n",
    "\n",
    "def write_to_db_by_category(row):\n",
    "    try:\n",
    "        conn = pymysql.connect(\n",
    "            host=os.getenv(\"DB_HOST\"),\n",
    "            port=int(os.getenv(\"DB_PORT\")),\n",
    "            user=os.getenv(\"DB_USER\"),\n",
    "            password=os.getenv(\"DB_PASSWORD\"),\n",
    "            database=os.getenv(\"DB_NAME\"),\n",
    "            charset='utf8mb4',\n",
    "            autocommit=True\n",
    "        )\n",
    "        with conn.cursor() as cursor:\n",
    "            club_id = get_club_id_by_name(cursor, row[\"club_name\"])\n",
    "            if not club_id:\n",
    "                log(f\"[SKIP] club_name ë§¤ì¹­ ì‹¤íŒ¨: {row['club_name']}\")\n",
    "                return\n",
    "\n",
    "            if row[\"category\"] == \"ëª¨ì§‘\":\n",
    "                sql = \"\"\"\n",
    "                    INSERT INTO ClubPromotion (clubId, target, dues, interview, endDate, isRecruiting)\n",
    "                    VALUES (%s, %s, %s, %s, %s, %s)\n",
    "                \"\"\"\n",
    "                cursor.execute(sql, (\n",
    "                    club_id,\n",
    "                    row.get(\"target\", \"ë¬´ê´€\"),\n",
    "                    row.get(\"dues\", 0),\n",
    "                    row.get(\"interview\", 0),\n",
    "                    row[\"deadline\"] if row[\"deadline\"] != \"ìƒì‹œ\" else None,\n",
    "                    1\n",
    "                ))\n",
    "                log(f\"âœ… ClubPromotion ì €ì¥: {row['title'][:20]}\")\n",
    "            else:\n",
    "                post_num = uuid.uuid4().hex\n",
    "                cursor.execute(\"\"\"\n",
    "                    INSERT INTO Post (postNum, title, content, type, file, `like`, fixaction, date)\n",
    "                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s)\n",
    "                \"\"\", (\n",
    "                    post_num,\n",
    "                    row[\"title\"],\n",
    "                    row[\"content\"],\n",
    "                    4,  # âœ… í™ë³´ í¬ìŠ¤í„°ë¡œ ê³ ì •\n",
    "                    None,\n",
    "                    0,\n",
    "                    0,\n",
    "                    datetime.now()\n",
    "                ))\n",
    "                cursor.execute(\"\"\"\n",
    "                    INSERT INTO ClubPost (postNum, clubId)\n",
    "                    VALUES (%s, %s)\n",
    "                \"\"\", (post_num, club_id))\n",
    "                for img_path in row.get(\"images\", []):\n",
    "                    cursor.execute(\"\"\"\n",
    "                        INSERT INTO Poster (postNum, img)\n",
    "                        VALUES (%s, %s)\n",
    "                    \"\"\", (post_num, img_path))\n",
    "                log(f\"âœ… Post + ClubPost + Poster ì €ì¥: {row['title'][:20]}\")\n",
    "        conn.close()\n",
    "    except Exception as e:\n",
    "        log(f\"[DB ERROR] ì €ì¥ ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "def load_start_time():\n",
    "    if os.path.exists(START_TIME_FILE):\n",
    "        log(\"ğŸ“ start_time.txt íŒŒì¼ ë°œê²¬ â†’ ë¶ˆëŸ¬ì˜´\")\n",
    "        with open(START_TIME_FILE, 'r') as f:\n",
    "            return datetime.strptime(f.read().strip(), DATETIME_FORMAT)\n",
    "    else:\n",
    "        log(\"ğŸ†• start_time.txt ì—†ìŒ â†’ ì‚¬ìš©ì ì…ë ¥ í•„ìš”\")\n",
    "        start_date = input('Start Date (YYYY-MM-DD): ')\n",
    "        dt = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "        save_start_time(dt)\n",
    "        return dt\n",
    "\n",
    "def save_start_time(dt):\n",
    "    with open(START_TIME_FILE, 'w') as f:\n",
    "        f.write(dt.strftime(DATETIME_FORMAT))\n",
    "\n",
    "def login_everytime(driver):\n",
    "    id = os.getenv(\"EVERYTIME_ID\")\n",
    "    pw = os.getenv(\"EVERYTIME_PW\")\n",
    "\n",
    "    if not id or not pw:\n",
    "        log(\"âŒ .envì— EVERYTIME_ID ë˜ëŠ” EVERYTIME_PWê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "\n",
    "    # ìë™í™” íƒì§€ ìš°íšŒ ìŠ¤í¬ë¦½íŠ¸ ì‚½ì…\n",
    "    driver.execute_cdp_cmd(\"Page.addScriptToEvaluateOnNewDocument\", {\n",
    "        \"source\": \"\"\"\n",
    "        Object.defineProperty(navigator, 'webdriver', {\n",
    "            get: () => undefined\n",
    "        })\n",
    "        \"\"\"\n",
    "    })\n",
    "\n",
    "    while True:\n",
    "        driver.get(\"https://account.everytime.kr/login\")\n",
    "        log(\"ğŸŒ Everytime ë¡œê·¸ì¸ í˜ì´ì§€ ë¡œë”© ì¤‘...\")\n",
    "        \n",
    "        try:\n",
    "            WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.NAME, 'id'))).send_keys(id)\n",
    "            driver.find_element(By.NAME, 'password').send_keys(pw)\n",
    "        except Exception as e:\n",
    "            log(f\"[ERROR] ë¡œê·¸ì¸ ì…ë ¥ì°½ ë¡œë”© ì‹¤íŒ¨: {e}\")\n",
    "            continue  # ì¬ì‹œë„\n",
    "\n",
    "        try:\n",
    "            ActionChains(driver).move_to_element(driver.find_element(By.CSS_SELECTOR, \"body\")).click().perform()\n",
    "            log(\"ğŸ–± ë¹ˆ ê³µê°„ í´ë¦­ ì™„ë£Œ (ìë™í™” ìš°íšŒ)\")\n",
    "        except Exception as e:\n",
    "            log(f\"[!] ë¹ˆ ê³µê°„ í´ë¦­ ì‹¤íŒ¨: {e}\")\n",
    "        time.sleep(2)\n",
    "        log(\"ğŸ”‘ ë¡œê·¸ì¸ ì‹œë„ ì¤‘...\")\n",
    "        driver.find_element(By.CSS_SELECTOR, 'input[type=\"submit\"]').click()\n",
    "        time.sleep(2)\n",
    "\n",
    "        try:\n",
    "            WebDriverWait(driver, 3).until(EC.alert_is_present())\n",
    "            alert = driver.switch_to.alert\n",
    "            log(f\"âš ï¸ ê²½ê³ ì°½ ê°ì§€: {alert.text}\")\n",
    "            alert.accept()\n",
    "            log(\"ğŸ”„ ë¡œê·¸ì¸ ì¬ì‹œë„ ì¤‘...\")\n",
    "            driver.refresh()\n",
    "            continue\n",
    "        except:\n",
    "            # ê²½ê³ ì°½ ì—†ìœ¼ë©´ ë¡œê·¸ì¸ ì„±ê³µ ì—¬ë¶€ í™•ì¸\n",
    "            if \"login\" in driver.current_url:\n",
    "                log(\"âš ï¸ ë¡œê·¸ì¸ ì‹¤íŒ¨: ê²½ê³ ì°½ì€ ì—†ì§€ë§Œ ë¡œê·¸ì¸ ìƒíƒœ ì•„ë‹˜ â†’ ì¬ì‹œë„\")\n",
    "                continue\n",
    "\n",
    "            log(\"âœ… ë¡œê·¸ì¸ ì„±ê³µ í™•ì¸ë¨\")\n",
    "            break\n",
    "\n",
    "\n",
    "def write_csv(row):\n",
    "    file_exists = os.path.exists('everytime_output.csv')\n",
    "    with open('everytime_output.csv', 'a', encoding='utf-8', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        if not file_exists:\n",
    "            writer.writerow(['ì‘ì„±ì¼ì‹œ', 'ì œëª©', 'ë‚´ìš©', 'ì¹´í…Œê³ ë¦¬', 'ë§ˆê°ì¼', 'ì „í™”ë²ˆí˜¸', 'URL', 'ë™ì•„ë¦¬ëª…', 'ì´ë¯¸ì§€ë“¤', 'ë™ì•„ë¦¬ë¶„ì•¼'])\n",
    "        writer.writerow(row)\n",
    "\n",
    "def download_image(img_url):\n",
    "    try:\n",
    "        if any(kw in img_url for kw in [\"nav.logo\", \"favicon\", \"cf-fpi.everytime.kr/0.png\"]):\n",
    "            log(f\"[SKIP] ë¶ˆí•„ìš” ì´ë¯¸ì§€ í•„í„°ë§ë¨: {img_url}\")\n",
    "            return \"\"\n",
    "\n",
    "        response = requests.get(img_url, timeout=10)\n",
    "        img = Image.open(BytesIO(response.content))\n",
    "\n",
    "        if img.mode in (\"RGBA\", \"P\"):\n",
    "            img = img.convert(\"RGB\")\n",
    "\n",
    "        # âœ… ë¹„ìœ¨ ìœ ì§€í•˜ë©° ìµœëŒ€ 720x1080 ì•ˆìœ¼ë¡œ ì¶•ì†Œ\n",
    "        max_width, max_height = 720, 1080\n",
    "        orig_w, orig_h = img.size\n",
    "        ratio = min(max_width / orig_w, max_height / orig_h, 1.0)  # ì›ë³¸ì´ ì‘ìœ¼ë©´ ê·¸ëŒ€ë¡œ\n",
    "        new_size = (int(orig_w * ratio), int(orig_h * ratio))\n",
    "        img = img.resize(new_size, Image.LANCZOS)\n",
    "\n",
    "        # âœ… ì €ì¥ ê²½ë¡œ\n",
    "        filename = f\"img_{uuid.uuid4().hex}.jpg\"\n",
    "        path = os.path.join(\"images\", filename)\n",
    "\n",
    "        # âœ… ê³ í™”ì§ˆ JPEG ì €ì¥\n",
    "        img.save(path, format=\"JPEG\", quality=95, optimize=True, progressive=True)\n",
    "\n",
    "        log(f\"ğŸ–¼ ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: {filename} ({new_size[0]}x{new_size[1]})\")\n",
    "        return filename\n",
    "\n",
    "    except Exception as e:\n",
    "        log(f\"[!] ì´ë¯¸ì§€ ì €ì¥ ì‹¤íŒ¨: {img_url} â†’ {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def parse_post_time(text):\n",
    "    now = datetime.now()\n",
    "    if 'ë°©ê¸ˆ' in text:\n",
    "        return now\n",
    "    if 'ë¶„ ì „' in text:\n",
    "        m = re.search(r'(\\d+)', text)\n",
    "        return now - timedelta(minutes=int(m.group(1))) if m else None\n",
    "    if re.match(r'\\d{2}/\\d{2} \\d{2}:\\d{2}', text):\n",
    "        month, day, hour, minute = map(int, re.findall(r'\\d+', text))\n",
    "        year = now.year\n",
    "        dt = datetime(year, month, day, hour, minute)\n",
    "        if dt > now and month in [11, 12]:\n",
    "            dt = datetime(year - 1, month, day, hour, minute)\n",
    "        return dt\n",
    "    if re.match(r'\\d{2}/\\d{2}$', text):\n",
    "        month, day = map(int, re.findall(r'\\d+', text))\n",
    "        year = now.year\n",
    "        dt = datetime(year, month, day)\n",
    "        if dt > now and month in [11, 12]:\n",
    "            dt = datetime(year - 1, month, day)\n",
    "        return dt\n",
    "    return None\n",
    "\n",
    "def extract_deadline(content, post_time):\n",
    "    content = re.sub(r'01[0-9][-\\.\\s]?[0-9]{3,4}[-\\.\\s]?[0-9]{4}', '', content)\n",
    "    range_patterns = [r'(\\d{1,2})[./](\\d{1,2})\\s*[~\\-]\\s*(\\d{1,2})[./](\\d{1,2})']\n",
    "    for pattern in range_patterns:\n",
    "        match = re.search(pattern, content)\n",
    "        if match:\n",
    "            sm, sd, em, ed = map(int, match.groups())\n",
    "            try:\n",
    "                deadline = datetime(post_time.year, em, ed)\n",
    "                if deadline < post_time:\n",
    "                    deadline = datetime(post_time.year + 1, em, ed)\n",
    "                return deadline.strftime(\"%Y-%m-%d\")\n",
    "            except:\n",
    "                continue\n",
    "    patterns = [\n",
    "        r'(\\d{4})ë…„\\s*(\\d{1,2})ì›”\\s*(\\d{1,2})ì¼',\n",
    "        r'(\\d{1,2})ì›”\\s*(\\d{1,2})ì¼',\n",
    "        r'(\\d{1,2})/(\\d{1,2})',\n",
    "        r'(?<!\\d)(0[1-9]|1[0-2])\\.(0[1-9]|[12][0-9]|3[01])(?!\\d)'\n",
    "    ]\n",
    "    for pattern in patterns:\n",
    "        matches = re.findall(pattern, content)\n",
    "        for match in matches:\n",
    "            try:\n",
    "                if len(match) == 3:\n",
    "                    year, month, day = map(int, match)\n",
    "                else:\n",
    "                    month, day = map(int, match)\n",
    "                    year = post_time.year\n",
    "                deadline = datetime(year, month, day)\n",
    "                if deadline < post_time:\n",
    "                    deadline = datetime(year + 1, month, day)\n",
    "                return deadline.strftime(\"%Y-%m-%d\")\n",
    "            except:\n",
    "                continue\n",
    "    if 'ë§¤ì£¼' in content or 'ë§¤ì¼' in content or 'ì •ê¸°' in content:\n",
    "        return None\n",
    "    return None\n",
    "\n",
    "def analyze_post(title, content, post_time, official_clubs):\n",
    "    category = \"í™ë³´\"\n",
    "    phone = \"\"\n",
    "\n",
    "    if \"ë°•ëŒíšŒ\" in title or \"ë°•ëŒíšŒ\" in content:\n",
    "        category = \"í™ë³´\"\n",
    "    elif \"ëª¨ì§‘\" in title or \"ëª¨ì§‘\" in content:\n",
    "        category = \"ëª¨ì§‘\"\n",
    "\n",
    "    phone_match = re.search(r'01[0-9][-]\\d{3,4}-\\d{4}', content)\n",
    "    if phone_match:\n",
    "        phone = phone_match.group()\n",
    "\n",
    "    combined_text = (title + \" \" + content)\n",
    "    simplified_text = re.sub(r'[^\\w]', '', combined_text).upper()\n",
    "\n",
    "    matched_club = \"\"\n",
    "    matched_category = \"\"\n",
    "    for key, info in official_clubs.items():\n",
    "        if key in combined_text or key in simplified_text:\n",
    "            matched_club = info.get(\"original\", key)\n",
    "            matched_category = info[\"category\"]\n",
    "            break\n",
    "\n",
    "    if matched_club:\n",
    "        club_name = matched_club\n",
    "    else:\n",
    "        club_name = \"\"\n",
    "\n",
    "    deadline = extract_deadline(content, post_time)\n",
    "    if category == \"í™ë³´\":\n",
    "        deadline = \"\"\n",
    "\n",
    "    return category, deadline, phone, club_name, matched_category\n",
    "\n",
    "def extract_images_excluding_profile(soup):\n",
    "    img_urls = []\n",
    "    for article in soup.select('article'):\n",
    "        all_imgs = article.select('img')\n",
    "        skip_first = True\n",
    "        for img in all_imgs:\n",
    "            src = img.get('src') or img.get('data-src') or img.get('lazy-src')\n",
    "            if not src:\n",
    "                continue\n",
    "            if skip_first or 'picture' in img.get('class', []) or src == 'https://cf-fpi.everytime.kr/0.png':\n",
    "                log(f\"[SKIP] í”„ë¡œí•„ ì´ë¯¸ì§€ ì œì™¸ë¨: {src}\")\n",
    "                skip_first = False\n",
    "                continue\n",
    "            if src.startswith('//'):\n",
    "                src = 'https:' + src\n",
    "            elif src.startswith('/'):\n",
    "                src = 'https://everytime.kr' + src\n",
    "            if re.search(r'\\.(png|jpg|jpeg|gif|webp)(\\?|$)', src, re.IGNORECASE):\n",
    "                img_urls.append(src)\n",
    "    return img_urls\n",
    "\n",
    "def run(driver, start_datetime, end_datetime):\n",
    "    official_clubs = load_official_club_info()\n",
    "    board_id = \"418897\"\n",
    "    base_url = f\"https://everytime.kr/{board_id}/p/\"\n",
    "    crawled_links = set()\n",
    "    if os.path.exists(CRAWLED_LINKS_FILE):\n",
    "        with open(CRAWLED_LINKS_FILE, 'r', encoding='utf-8') as f:\n",
    "            crawled_links = set(f.read().splitlines())\n",
    "\n",
    "    for page in range(1, 1000):\n",
    "        try:\n",
    "            url = base_url + str(page)\n",
    "            log(f\"[DEBUG] â–¶ í˜ì´ì§€ ì´ë™: {url}\")\n",
    "            driver.get(url)\n",
    "            time.sleep(2)\n",
    "            WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, 'articles')))\n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            articles = soup.select(\"article\")\n",
    "            valid_post_count = 0\n",
    "            for article in articles:\n",
    "                link_tag = article.find(\"a\", href=True)\n",
    "                if not link_tag or not link_tag.has_attr(\"href\"):\n",
    "                    continue\n",
    "                href = link_tag['href']\n",
    "                if not re.search(r\"/v/\\d+\", href):\n",
    "                    continue\n",
    "                time_tag = link_tag.find(\"time\")\n",
    "                if not time_tag:\n",
    "                    continue\n",
    "                post_time = parse_post_time(time_tag.text.strip())\n",
    "                if not post_time or not (start_datetime <= post_time < end_datetime):\n",
    "                    continue\n",
    "                full_url = f\"https://everytime.kr{href}\"\n",
    "                if full_url in crawled_links:\n",
    "                    continue\n",
    "\n",
    "                driver.get(full_url)\n",
    "                WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.TAG_NAME, 'article')))\n",
    "                soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "                post = soup.find(\"article\")\n",
    "                title = post.h2.text.strip()\n",
    "                content = post.find('p').get_text(separator='\\n').strip()\n",
    "                category, deadline, phone, club_name, club_category = analyze_post(title, content, post_time, official_clubs)\n",
    "                if 'í”¼í—˜ì' in title or 'í”¼í—˜ì' in content:\n",
    "                    log(f\"[SKIP] í”¼í—˜ì ëª¨ì§‘ ê°ì§€: {title[:20]}... ({club_name})\")\n",
    "                    continue\n",
    "\n",
    "                semester = f\"{post_time.year}-S{1 if post_time.month <= 6 else 2}\"\n",
    "                if f\"{semester}|{title.strip()}\" in crawled_links:\n",
    "                    log(f\"[SKIP] ì œëª© ì™„ì „ ì¼ì¹˜ ì¤‘ë³µ ê°ì§€: {title[:20]}... ({club_name})\")\n",
    "                    continue\n",
    "\n",
    "                is_similar = False\n",
    "                for key in crawled_links:\n",
    "                    if key.startswith(semester):\n",
    "                        existing_title = key.split('|', 1)[-1]\n",
    "                        tfidf = TfidfVectorizer().fit_transform([title.strip(), existing_title])\n",
    "                        sim = cosine_similarity(tfidf[0:1], tfidf[1:2])[0][0]\n",
    "                        if sim > 0.85:\n",
    "                            log(f\"[SKIP] ìœ ì‚¬ ì œëª© ì¤‘ë³µ ê°ì§€ (cos {sim:.2f}): {title[:20]}... ({club_name})\")\n",
    "                            is_similar = True\n",
    "                            break\n",
    "                if is_similar:\n",
    "                    continue\n",
    "\n",
    "                # ì´ë¯¸ì§€ ì¶”ì¶œ ë° ì €ì¥\n",
    "                img_urls = extract_images_excluding_profile(soup)\n",
    "                saved_imgs = [download_image(img_url) for img_url in img_urls]\n",
    "\n",
    "                write_to_db_by_category({\n",
    "                    \"title\": title,\n",
    "                    \"content\": content,\n",
    "                    \"category\": category,\n",
    "                    \"deadline\": deadline if deadline else \"ìƒì‹œ\",\n",
    "                    \"phone\": phone,\n",
    "                    \"url\": full_url,\n",
    "                    \"club_name\": club_name,\n",
    "                    \"images\": saved_imgs\n",
    "                })\n",
    "\n",
    "                crawled_links.add(full_url)\n",
    "                crawled_links.add(f\"{semester}|{title.strip()}\")\n",
    "                log(f\"ğŸ“„ {post_time.strftime('%m/%d')} - {title} [{category}] ({club_name}) ì €ì¥\")\n",
    "                valid_post_count += 1\n",
    "\n",
    "            if valid_post_count == 0:\n",
    "                log(\"ğŸ›‘ í˜„ì¬ í˜ì´ì§€ ëª¨ë“  ê²Œì‹œê¸€ì´ ë²”ìœ„ ë°– â†’ í¬ë¡¤ë§ ì¢…ë£Œ\")\n",
    "                break\n",
    "\n",
    "        except Exception as e:\n",
    "            log(f\"[!] í˜ì´ì§€ {page} ì²˜ë¦¬ ì‹¤íŒ¨: {e}\")\n",
    "            continue\n",
    "\n",
    "def main():\n",
    "    while True:\n",
    "        start_datetime = load_start_time()\n",
    "        end_datetime = datetime.now()\n",
    "        options = webdriver.ChromeOptions()\n",
    "        options.add_argument('window-size=1200x800')\n",
    "        driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "        login_everytime(driver)\n",
    "        log(f\"ğŸŒ í¬ë¡¤ë§ ì‹œì‘: {end_datetime.strftime(DATETIME_FORMAT)}\")\n",
    "        log(f\"ğŸ“† í¬ë¡¤ë§ ë²”ìœ„: {start_datetime.strftime(DATETIME_FORMAT)} ~ {end_datetime.strftime(DATETIME_FORMAT)}\")\n",
    "        run(driver, start_datetime, end_datetime)\n",
    "        save_start_time(end_datetime)\n",
    "        driver.quit()\n",
    "        log(\"â³ 1ì‹œê°„ ëŒ€ê¸° ì¤‘...\\n\")\n",
    "        time.sleep(3600)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
